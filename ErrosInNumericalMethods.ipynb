{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKne9x3Vgibs2UaCXuNh74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidrezanorouzi/pythonTempFiles/blob/main/ErrosInNumericalMethods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Errors in Numerical Methods**"
      ],
      "metadata": {
        "id": "zKCFK_wccRQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notes**‚ùï\n",
        "This document is a part of the course lectures of **`numeical methods in chemical engineering`** for B.Sc. students of chemical engineering at Amirkabir univeristy of Technology.\n",
        "\n",
        "You can use the content and the source codes in this document with proper referencing the original document.\n",
        "\n",
        "All the art-work contents of this document are obtained from the\n",
        "following sources, unless otherwise stated:\n",
        "* Steven C. Chapra, Applied Numerical Methods with Mathlab for Engineers and Scientists, 3rd eddition, McGraw-Hill (2012).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sfFhUVkMkDXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  üîµ 1) Why do we use numerical methods in chemical engineering?\n",
        "\n",
        "We always deal with mathematical equations in real-world engineering problems:\n",
        "*   We describe physical phenomena using mathematical equations\n",
        "*   We use mathematical equations to relate physical properties to state variables (Temperature, pressure, etc.)\n",
        "*   We deal with measured data and we need to perform data reduction (finding a mathematical relation between variables) or directly use them in engineering computations\n",
        "\n",
        "To solve an engineering problem, a bunch of mathematical equations are present. we always need numeical methods and computers to solve the equations and perform the required calculations.  \n",
        "\n",
        "<div align=\"center\">\n",
        "üîπüîπüîπ\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cUgOnjysiVG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü¢ 2) Numerical methods and quantifying errors\n",
        "## 2-1) True error\n",
        "* A Numecial method employs **approximations** to represent an equation or to  calculate the exact quantities.\n",
        "* Therefore, we are always some deviations from exact solution, called **error**. So, we always have:\n",
        "$$\n",
        "trueValue = approximation + error  \\tag{1}\n",
        "$$\n",
        "\n",
        "* Rearranging the above equaiton will give **true error**:\n",
        "$$\n",
        "E_{t} = trueValue - approximation \\tag{2}\n",
        "$$\n",
        "\n",
        "* Eq. (2) does not reflect the magnitude of the numbers. So we use relative errors, usaully expressed in precent, **true percent relative error**:\n",
        "$$\n",
        "œµ_{t}=\\frac{trueValue-approximation}{trueValue} * 100\\% \\tag{3}\n",
        "$$\n",
        "note that we always use the **absolute** of the above value as error.\n",
        "\n",
        "&nbsp;\n",
        "\n"
      ],
      "metadata": {
        "id": "HpFkDel3lzrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì **Example 1:**\n",
        "Compute the true error and true percent relative error in the following meaturements:\n",
        "\n",
        "(A) A pen: true length = 10 cm, measured leangth = 11 cm\n",
        "\n",
        "(B) A pipe: true length = 1000 cm,  measured length = 1001 cm\n",
        "\n",
        "### üí° *solution*\n",
        "\n",
        "(A)\n",
        "\n",
        "$$\n",
        "E_{t}= |11 - 10| = 1 \\ cm \\\\\n",
        "œµ_{t}=|\\frac{10-11}{10}|*100\\% = 10\\%\n",
        "$$\n",
        "(B)\n",
        "$$\n",
        "E_{t}= |1000 - 1001| = 1 \\ cm \\\\\n",
        "œµ_{t}=|\\frac{1000-1001}{1000}|*100\\% = 0.1\\%\n",
        "$$"
      ],
      "metadata": {
        "id": "bkqlZfxdNLcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-2) Approximate error\n",
        "* In numerical methods, we usually have approximation error instead of true error. So we define the approximation error as:\n",
        "$$\n",
        "œµ_{a}=\\frac{approximation \\ error}{approximation} √ó 100\\% \\tag{4}\n",
        "$$\n",
        "\n",
        "* and in iterative methods, we rewrite the equation as:\n",
        "$$\n",
        "œµ_{a}=\\frac{present \\ approximation - previous \\ approximation}{present \\ approximation} √ó 100\\% \\tag{5}\n",
        "$$"
      ],
      "metadata": {
        "id": "bhgGNszSh1oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì **Example 2:**\n",
        "Approximate the exponential function at x = 0.5 using McLaurin\n",
        "series. The approximated value should have 0.05% precision.\n",
        "$$\n",
        "e^x = 1+x+\\frac{x^2}{2!}+\\frac{x^3}{3!}+...+\\frac{x^n}{n!}\n",
        "$$\n",
        "\n",
        "### üí° *solution*\n",
        "We stop adding terms from Mclaurin series when the relative precent approximate error is less than 0.05%."
      ],
      "metadata": {
        "id": "VVsa7Nrdpnhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = 0.5\n",
        "term = 1\n",
        "app = term\n",
        "prevApp = app\n",
        "trueValue = np.exp(x)\n",
        "\n",
        "print(\"%7s|%14s|%14s|%14s\" %(\"Terms\",\"Approxiamte\",\"true Error (%)\",\"App. Error (%)\"))\n",
        "\n",
        "for i in range(1,30):\n",
        "  term *= x/(i)\n",
        "  app += term\n",
        "  ep = np.abs(trueValue-app)/trueValue*100\n",
        "  eApp = np.abs(prevApp-app)/app*100\n",
        "  prevApp = app\n",
        "  print(\"%7d|%14.6f|%14.6f|%14.6f\" %(i+1, app, ep, eApp) )\n",
        "  if eApp<0.05:\n",
        "    break\n"
      ],
      "metadata": {
        "id": "DZ7slj9Zlwh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9267d1-e72d-4465-f717-7e026ec6e0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Terms|   Approxiamte| trueError (%)|App. Error (%)\n",
            "      2|      1.500000|      9.020401|     33.333333\n",
            "      3|      1.625000|      1.438768|      7.692308\n",
            "      4|      1.645833|      0.175162|      1.265823\n",
            "      5|      1.648438|      0.017212|      0.157978\n",
            "      6|      1.648698|      0.001416|      0.015795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align =\"center\">\n",
        "üü©üü©üü©\n",
        "</div>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hTdgZHEGl-uV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü£ 3) Representation of numbers in computers\n",
        "## 3-1) Integer numbers  \n",
        "* Numbers are stored in the memory of the computer in binary (base 2) form.\n",
        "* Each binray digit (may contain 0 or 1) is called a bit.\n",
        "* An integer number with base 10 is first converted to base 2 and then are stored in the bits of memory with zeros and ones.\n",
        "* For example 173 in base-10 can be represented in binray:\n",
        "$$\n",
        "(10101101)_{2} = 1\\times 2^7 + 0\\times2^6 + 1\\times 2^5 + 0 \\times2^4 + 1\\times2^3 + 1\\times2^2 + 0 \\times 2^1 + 1 \\times 2^0 = (173)_{10}\n",
        "$$"
      ],
      "metadata": {
        "id": "y8EOE1vSFfbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "u3W-LDoRZbfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f2d3b8-b7e9-4329-f850-ab5778574347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decimal: 173 ==> binray: 0b10101101\n",
            "decimal: -173 ==> binray: -0b10101101\n",
            "decimal: 65536 ==> binray: 0b10000000000000000\n",
            "decimal: 4294967296 ==> binray: 0b100000000000000000000000000000000\n",
            "type of variable c is <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "a: int = 173\n",
        "b = pow(2,16)\n",
        "c = pow(2,32)\n",
        "\n",
        "print(f'decimal: {a} ==> binray: {bin(a)}')\n",
        "print(f'decimal: {-a} ==> binray: {bin(-a)}')\n",
        "print(f'decimal: {b} ==> binray: {bin(b)}')\n",
        "print(f'decimal: {c} ==> binray: {bin(c)}')\n",
        "print(f'type of variable c is {type(c)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In python, the length of integer numbers (number of bits dedicated to it) is unlimited. So we can store very large integers in memory.\n",
        "* In other languages like, C, C++ and Fortran, we need to specify the length of integer number. For example in C++, we may use 8 (`char`), 16 (`short`), 32 (`int`)or 64 (`long int`) bits for integer numbers."
      ],
      "metadata": {
        "id": "VBpOC0ZCp6PX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2) Floating point numbers\n",
        "* Large and small floating point numbers can be represented using decimal notation (also called scientific notation):\n",
        "$$\n",
        "d.dddddd \\times10^p \\tag{6}\n",
        "$$\n",
        "* The digits to the left of decimal point is called **mantissan** and represent the number of significant digits.\n",
        "$$ 0.dddddd $$\n",
        "* For example:\n",
        " * $0.000193$ is represented as $1.93 \\times 10^{-5}$: it has two significant digits and is of order of $O(10^{-6})$\n",
        " * $6543.743$ is represented as $6.543743\\times10^{3}$: it has six significant digits and is of order of $O(10^4)$.\n",
        "\n",
        "* If we had bits that could store numbers 0 to 9, then the decimal representation of the number could be used for storing numbers in computer memory.\n",
        "* For $6.543743\\times10^{3}$ the mantissa is $0.543743$ and it can be written as\n",
        " $$5\\times10^{-1}+4\\times10^{-2}+3\\times10^{-3}+7\\times10^{-4}+4\\times10^{-5}+3\\times10^{-6} = 0.543743$$"
      ],
      "metadata": {
        "id": "dOo5n1FQQWnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Computer memory can store binary numbers, so the floating point numbers should be expressed in terms of zeros and ones:\n",
        "$$\n",
        "1.bbbbbb\\times2^{bbb} \\tag{7}\n",
        "$$\n",
        "where $1.bbbbbb$ is **mantissa** and $bbb$ is **exponent**.\n",
        "\n",
        "* For example:\n",
        "$$\n",
        "(0.3125)_{10} = \\frac{0.3125}{2^{-2}}\\times{2^{-2}} = 1.25\\times2^{-2} = (1.01\\times2^{-10})_{2} \\\\\n",
        "\\text{where    } (0.25)_{10} = 0\\times2^{-1}+1\\times2^{-2}\n",
        "$$"
      ],
      "metadata": {
        "id": "Vfhm4Drh0C4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-3) How to store floating point numbers in computer memory?\n",
        "* In computer memory the floating point numbers are stroed in bits based on the IEEE-754 standard (1985).\n",
        " * single precision uses 32 bits\n",
        " * double precision uses 64 bits\n",
        "* **Single precision (32 bit)**\n",
        " * The first bit is for sign\n",
        " * The next 8 bits is for exponent\n",
        " * The rest of 23 bits for mantissa\n",
        " * remember our last example, the binary representation of 0.3125:\n",
        " $$(0.3125)_{10} = (1.01\\times2^{-10})_{2} \\\\\n",
        "  0-01111101-01000000000000000000000$$\n",
        "  You can test the decimal to binary conversion using this [online tool](https://www.h-schmidt.net/FloatConverter/IEEE754.html). Note that the exponent is added to a bias 127.\n",
        "\n",
        "* **Double precision (64 bit)**\n",
        " * The first bit is for sign\n",
        " * The next 11 bits for expoenent\n",
        " * The rest of 52 bits for mantissa"
      ],
      "metadata": {
        "id": "cndzfUDw8VrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-4) Properties of double precision\n",
        "* Floating point number in python is double precision type and is called `float`\n",
        "* The smallest exponent with 11 digits is -1023 and the largest expoenent is 1024\n",
        "* The smallest positive number is:\n",
        "$$ 2^{-1022} = 2.2\\times10^{-308} $$\n",
        "  any positive value smaller than this cannot be stored in the computer memory it is called **underflow**.\n",
        "* The largest positive number is:\n",
        "$$\n",
        "2^{1024} = 1.8\\times10^{308}\n",
        "$$\n",
        "any number larger than this cannot be stored in the memory and it is called **overflow**."
      ],
      "metadata": {
        "id": "LJdnb-mGCC1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=15xwZjnhJSg0JTv7DgovO_4sTCPSz2pBc\" width=\"600\" />\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "iZaOPCmIFx4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"largest positive floating point (double)\", sys.float_info.max)\n",
        "print(\"smallest positive floating point (double)\", sys.float_info.min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saEbSwFt8bl9",
        "outputId": "10e4823b-a1f7-4c00-e0bf-904fc7179fbb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "largest positive floating point (double) 1.7976931348623157e+308\n",
            "smallest positive floating point (double) 2.2250738585072014e-308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The precision of the float number is defined as the smallest value of mantissa that can be stored:\n",
        "$$\n",
        "2^{-52} = 2.22\\times10^{-16}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "6JwRPAJrNJLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"epsilon = \", sys.float_info.epsilon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2bETgcHHvTP",
        "outputId": "d1f18860-a5c9-4754-e535-109b5c027536"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epsilon =  2.220446049250313e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "üíúüíúüíú\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4jZFiqBC3BU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü° 4) Errors in numerical methods\n",
        "\n",
        "## 4-1) Round-off error\n",
        "* Since the computer use a finite number of bits for storing mantissa and exponents of floating point numbers, not every number can be accuratly represented in binary format.\n",
        "* For example 1.1 cannot be represented exactly with double-precision model. But 0.5 can be represented preciesly with double-precision model."
      ],
      "metadata": {
        "id": "lj2YqANkPX8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x: float = 1.1\n",
        "y: float = 0.5\n",
        "print(\"%.17e\" %(x))\n",
        "print(\"%.17e\" %(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhXK58FzQuXt",
        "outputId": "a9ba80ba-ed4f-4127-b301-f9a4ca48285a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10000000000000009e+00\n",
            "5.00000000000000000e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* When a mathematical operation is performed between two numbers, the computer may commit a round-off error."
      ],
      "metadata": {
        "id": "NGyoTO9cSOHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = 5.0e-7\n",
        "l = 5.0e+9\n",
        "print(\"exact value of s: %.17e\" %(s))\n",
        "print(\"exact value of l: %.17e\" %(l))\n",
        "print(\"sum: %.17e\" %(s+l))\n",
        "print(\"subtract: %.17e\" %(l-s))\n",
        "print(\"product: %.17e\" %(s*l))\n",
        "print(\"division: %.17e\" %(s/l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3gtpsxcSm0l",
        "outputId": "be03efa9-c5e4-4d61-d4e9-b170b4491cb9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exact value of s: 4.99999999999999977e-07\n",
            "exact value of l: 5.00000000000000000e+09\n",
            "sum: 5.00000000000000095e+09\n",
            "subtract: 4.99999999999999905e+09\n",
            "product: 2.50000000000000000e+03\n",
            "division: 9.99999999999999979e-17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-2) Truncation error\n",
        "* Truncation error occurs when numerical approximations are used in place of exact mathematical formulas.\n",
        "* For example, consider approximation of the first derivative of a function using finite-difference equation:\n",
        "$$\n",
        "\\frac{df(x)}{dx} ‚âÉ \\frac{Œîf}{Œîx} = \\frac{f(x_2)-f(x_1)}{x_2-x_1} \\tag{8}\n",
        "$$\n",
        "\n",
        "* The above equation does not give us the exact value of the first derivative, but an approximate of it. So, it causes some **error** in the calculations, which we call **truncation error**.\n"
      ],
      "metadata": {
        "id": "M_t1hu9VHdUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def fx(x):\n",
        "  return x*math.sin(x)\n",
        "\n",
        "def dfx(x):\n",
        "  return math.sin(x) + x*math.cos(x)\n",
        "\n",
        "def approximateDf(func, x, eps = 0.01):\n",
        "  return (func(x+eps)-func(x))/eps\n",
        "\n",
        "x = 1.55\n",
        "exact = dfx(x)\n",
        "approximate = approximateDf(fx, x)\n",
        "print(f'df at {x}: exact value is {exact} and approximate value is {approximate}')\n",
        "print(f'Error is {abs(exact-approximate)/exact*100:7.3f} %')"
      ],
      "metadata": {
        "id": "SRZr0fnDJvf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Consider Taylor expansion series around $x_i$ with $x_{i+1} = x_i+h$:\n",
        "\n",
        "\n",
        "$$\n",
        "f(x_{i+1}) = f(x_i) + f^{'}(x_i)h+\\frac{f^{\"}(x_i)}{2!}h^2+...+\\frac{f^n(x_i)}{n!}h^n + R_n  \\tag{9}\n",
        "$$\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=1MMZ9Pd8PQrxyKcu8wNzDPwn0dm2zOdEK\" width=\"400\" />\n",
        "</div>"
      ],
      "metadata": {
        "id": "4U0xlLWBMg2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In general, the nth-order Taylor series expansion will be exact for an nth-order polynomial.\n",
        "* For other differentiable and continuous functions, such as exponentials and sinusoids, a finite number of terms will not yield an exact estimate.\n",
        "* Each additional term will\n",
        "contribute some improvement, however slight, to the approximation.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "17fTTlrZ3bQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The reminder is:\n",
        "$$\n",
        "R_n = \\frac{f^{n+1}(\\xi)}{(n+1)!}h^{n+1} \\tag{10}\n",
        "$$\n",
        "* We can re-express it as:\n",
        "$$ R_n = O(h^{n+1})  \\tag{11}\n",
        "$$\n",
        "* Although this notation does not give us the exact value of error (truncation error), but it is useful for judging the change in the error when changing the step size *h*.\n",
        "\n",
        "* if the error is of $O(h^2)$, then halving the step size h, will approximately reduce the error 4 times.\n"
      ],
      "metadata": {
        "id": "eCodnlQj4Wrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì **Example 3:**\n",
        "Estimate the $f(x) = cos(x)$ at $x = \\pi/6$ using Taylor expansions series at $x = 0$.\n",
        "\n",
        "### üí° Solution\n",
        "We use the Taylor series around $x_i = 0$  with $h =\\pi/6$  and  $f(x_i) = cos(x_i)$. The exact value of function at   $\\pi/6$   is 0.8660254038\n",
        "\n",
        " - With one term of of series:\n",
        "\n",
        "  $\\begin{aligned} f(\\pi/6) ‚âÉ f(0) = 1\\end{aligned}$\n",
        "  \n",
        "  $\\begin{aligned}\n",
        "  œµ_t = |\\frac{0.86602504038-1}{0.86602504038}| \\times 100 = 15.47 \\%\n",
        "  \\end{aligned}$\n",
        "\n",
        " - with two terms, the second term is added:\n",
        "\n",
        "  $\\begin{aligned} -sin(0)*\\pi/6 = 0\\end{aligned}$\n",
        "  \n",
        "  and the approximate will be 1.\n",
        "\n",
        " - with three terms, the thirs term is added:\n",
        "  \n",
        "  $\\begin{aligned} -cos(0)*(\\pi/6)^2 = -0.13707784\\end{aligned}$\n",
        "\n",
        "  $\\begin{aligned}\n",
        "  f(\\pi/6) ‚âÉ 1 - 0 -0.13707784 = 0.86292216 \\\\\n",
        "  œµ_t = |\\frac{0.86602504-0.86292216}{0.86602504}| \\times 100 = 0.35 \\%\n",
        "  \\end{aligned}$\n"
      ],
      "metadata": {
        "id": "m3NULBTj6Nzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code for Example 3**"
      ],
      "metadata": {
        "id": "Ue2WDe61hK4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def dfx(x , n=0):\n",
        "  if n%2 == 0:\n",
        "    res = math.cos(x)\n",
        "  else:\n",
        "    res = math.sin(x)\n",
        "\n",
        "  e = int((n+1)/2)\n",
        "  return res *math.pow(-1, e)\n",
        "\n",
        "x = 0\n",
        "tol = 0.5\n",
        "h = math.pi/6.0\n",
        "exact = math.cos(math.pi/6.0)\n",
        "approximate = 0\n",
        "\n",
        "for i in range (30):\n",
        "  term = dfx(x,i) * math.pow(h,i)/math.factorial(i)\n",
        "  approximate += term\n",
        "  et = abs(approximate-exact)/exact*100\n",
        "  print(f'{i+1:3d} - function approximate is {approximate:10.8f}'\n",
        "        f' and true error is {et:6.3f} %')\n",
        "  if et <tol :\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NR4D3slnqvz",
        "outputId": "facc7644-d2c9-4082-9c43-02c42bdc6364"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1 - function approximate is 1.00000000 and true error is 15.470 %\n",
            "  2 - function approximate is 1.00000000 and true error is 15.470 %\n",
            "  3 - function approximate is 0.86292216 and true error is  0.358 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-3) Total error\n",
        "* The *total numerical error* is the summation of the truncation and roundoff errors.\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=1SLszX-3oYQk5lWzt3FjHIoMYggVMCFop\" width=\"500\" />\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "kAaRVIxEhEhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align = \"center\">\n",
        "üü®üü®üü®\n",
        "</div>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ucfgcwwLm1J8"
      }
    }
  ]
}